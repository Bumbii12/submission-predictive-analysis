# -*- coding: utf-8 -*-
"""hotel.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/16JITiqW0ygy5bvY3EYG1n_Un3b-Dpo_F

# Proyek Analisis Sentimen: [Trip Advisor Hotel Reviews]
- **Nama:** Ulfa Stevi Juliana
- **Email:** steviulpa@Gmail.coom
- **ID Dicoding:** MC189D5X2331

#Import library
"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns

import re
from sklearn.model_selection import train_test_split
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics import accuracy_score, classification_report
from tensorflow.keras.preprocessing.text import Tokenizer
import spacy
from sklearn.feature_extraction.text import CountVectorizer
from tqdm import tqdm
tqdm.pandas()

"""#Data preparation

Pada tahap ini, dataset akan disiapkan sehingga siap untuk masuk ketahap permodelan

##Data loading

Pada tahap ini saya memuat dataset review hotel dengan format CSV. Dataset dapat diunduh pada link ini [Kaggle-Trip Advisor Hotel Reviews](https://www.kaggle.com/datasets/andrewmvd/trip-advisor-hotel-reviews).
"""

df = pd.read_csv('tripadvisor_hotel_reviews.csv')
df.head()

"""##Data understanding

insight : Dataset dalam dataset sudah dimasukkan ke dalam dataframe **df**. Dapat dilihat bahwa terdapat dua kolom yaitu **Review** dengan data berbahasa inggris dan **Rating**

###Melakukan pengecekan dimensi data
"""

df.shape

"""insight : dataset memiliki 20.491 baris data dengan jumlah kolom sebanyak dua

###Melakukan pengecekan missing values pada semua fitur
"""

df.isnull().sum()

"""Insight : dapat dilihat bahwa tidak terdapat missing values

###Melihat persebaran data untuk setiap Rating **(1 hingga 5)**
"""

sns.countplot(data=df,x='Rating')

"""Insight : dapat dilihat bahwa persebaran data setiap rating memiliki urutan terbanyak hingga tersedikit yaitu : 5, 4, 3, 2, 1.

#Encoding label sentimen

Pada tahapan ini label rating akan menjadi label sentimen dengan ketentuan :


*   Rating 1,2, dan 3 : Negatif (0)
*   Rating 4 dan 5 : Positif (1)
"""

def label_encode(x):
    if x == 1 or x == 2 or x == 3 :
        return 0
    if x == 4 or x == 5:
        return 1

def label_name(x):
    if x == 0:
        return "Negative"
    if x == 1:
        return "Positive"

"""Transformasi DataFrame:


*   menggunakan fungsi *label_encode()* yang hasilnya dimasukkan ke kolom baru bernama **sentimen**
*   menggunakan fungsi *label_name()* yang hasilnya adalah string sentimen berdasarkan kolom **sentimen** dimasukkan ke kolom baru bernama **sentimen_name**


"""

df["sentiment"] = df["Rating"].apply(lambda x: label_encode(x))
df["sentiment_name"] = df["sentiment"].apply(lambda x: label_name(x))

df.head()

"""Insight : Dapat dilihat bahwa Dataframe sudah berhasil ditambahkan label sentimennya

#Data Preprosessing

Fungsi clean_text() melakukan pembersihan teks dengan langkah-langkah berikut:

* Menghapus tag HTML

* Menghilangkan URL

* Mengonversi emoji ke teks

* Menghapus angka

* Menghapus tanda baca

* Menghapus stopwords

* Melakukan stemming
"""

!pip install emoji

import re
import emoji
import string
import nltk
nltk.download('stopwords')
from nltk.corpus import stopwords
from nltk.stem import PorterStemmer

# Inisialisasi stopwords dan stemmer
stop_words = set(stopwords.words('english'))
ps = PorterStemmer()

def clean_text(text):
    # 1. Remove HTML tags
    text = re.sub(r'<.*?>', '', text)

    # 2. Remove URLs
    text = re.sub(r'https?://\S+|www\.\S+', '', text)

    # 3. Convert emojis to text (e.g., üòÉ -> :smile:)
    text = emoji.demojize(text)

    # 4. Remove digits
    text = re.sub(r'\d+', '', text)

    # 5. Remove punctuation
    text = text.translate(str.maketrans('', '', string.punctuation))

    # 6. Remove stopwords
    text = ' '.join(word for word in text.split() if word.lower() not in stop_words)

    # 7. Stemming
    text = ' '.join(ps.stem(word) for word in text.split())

    return text

df['Review'] = df['Review'].apply(clean_text)
df.head()

"""Insight : Dapat dilihat bahwa data di kolom review sudah berubah sesuai dengan format yang diatur dalam fungsi *clean_text()*

#Data Spliting 70/30

Sebelum Data Spliting, data terlebih dahulu di pisahkan antara data input (kolom Review) dan output (kolom sentimen).

Kemudian, barulah data displit menjadi :


* X_train.shape: ukuran data input untuk pelatihan

* X_test.shape: ukuran data input untuk pengujian

* y_train.shape: ukuran label pelatihan

* y_test.shape: ukuran label pengujian
"""

X = df.drop(['sentiment', 'sentiment_name', 'Rating'], axis=1)
y = df['sentiment']

from sklearn.model_selection import train_test_split
X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.3,random_state=1,stratify=y)
X_train.shape,X_test.shape,y_train.shape,y_test.shape

"""Insight : Output ((14343, 1), (6148, 1), (14343,), (6148,)) menunjukkan bahwa data telah dibagi menjadi 14.343 data latih dan 6.148 data uji, masing-masing dengan 1 fitur dan 1 label.

#Tokenization with BERT Tokenizer

Kode ini mempersiapkan data teks dan label untuk digunakan dalam model BERT. Proses meliputi tokenisasi teks ulasan dengan padding dan truncation, serta konversi label menjadi tensor PyTorch. Tokenizer yang digunakan adalah bert-base-uncased dari HuggingFace.
"""

!pip install transformers
!pip install datasets

import torch
from transformers import BertTokenizer, BertForSequenceClassification
from torch.optim import AdamW
from sklearn.model_selection import train_test_split
from torch.utils.data import DataLoader, TensorDataset, RandomSampler, SequentialSampler

from transformers import BertTokenizer

tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')

# Ambil kolom teks
train_texts = X_train['Review'].tolist()
test_texts = X_test['Review'].tolist()

# Tokenisasi dan padding
train_encodings = tokenizer(
    train_texts,
    truncation=True,
    padding=True,
    max_length=128,
    return_tensors='pt'
)

test_encodings = tokenizer(
    test_texts,
    truncation=True,
    padding=True,
    max_length=128,
    return_tensors='pt'
)

# Konversi label ke tensor
train_labels = torch.tensor(y_train.values)
test_labels = torch.tensor(y_test.values)

"""#Model Training

Kode ini melatih model BERT untuk klasifikasi sentimen menggunakan PyTorch dan HuggingFace. Proses mencakup:

* Membuat TensorDataset dan DataLoader dari data tokenized.

* Menginisialisasi model BertForSequenceClassification dan optimizer AdamW.

* Melakukan pelatihan selama beberapa epoch.

* Mencatat loss dan akurasi pada data latih dan validasi.
"""

from torch.utils.data import DataLoader, TensorDataset, RandomSampler, SequentialSampler

# Buat TensorDataset
train_dataset = TensorDataset(
    train_encodings['input_ids'],
    train_encodings['attention_mask'],
    train_labels
)

test_dataset = TensorDataset(
    test_encodings['input_ids'],
    test_encodings['attention_mask'],
    test_labels
)

# Buat DataLoader
train_loader = DataLoader(train_dataset, sampler=RandomSampler(train_dataset), batch_size=16)
val_loader = DataLoader(test_dataset, sampler=SequentialSampler(test_dataset), batch_size=16)

from transformers import BertForSequenceClassification
from torch.optim import AdamW

device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

model = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=2)
model.to(device)

optimizer = AdamW(model.parameters(), lr=5e-5)

from tqdm import tqdm

epochs = 3
train_losses = []
val_losses = []
train_accuracies = []
val_accuracies = []

for epoch in range(epochs):
    # Training phase
    model.train()
    total_train_loss = 0
    correct_train_predictions = 0
    total_train_samples = 0

    for batch in tqdm(train_loader):
        optimizer.zero_grad()

        input_ids = batch[0].to(device)
        attention_mask = batch[1].to(device)
        labels = batch[2].to(device)

        outputs = model(input_ids, attention_mask=attention_mask, labels=labels)
        loss = outputs.loss
        logits = outputs.logits

        loss.backward()
        optimizer.step()

        total_train_loss += loss.item()
        predictions = torch.argmax(logits, dim=-1)
        correct_train_predictions += (predictions == labels).sum().item()
        total_train_samples += labels.size(0)

    train_losses.append(total_train_loss / len(train_loader))
    train_accuracies.append(correct_train_predictions / total_train_samples)

    # Validation phase
    model.eval()
    total_val_loss = 0
    correct_val_predictions = 0
    total_val_samples = 0

    with torch.no_grad():
        for batch in val_loader:
            input_ids = batch[0].to(device)
            attention_mask = batch[1].to(device)
            labels = batch[2].to(device)

            outputs = model(input_ids, attention_mask=attention_mask, labels=labels)
            loss = outputs.loss
            logits = outputs.logits

            total_val_loss += loss.item()
            predictions = torch.argmax(logits, dim=-1)
            correct_val_predictions += (predictions == labels).sum().item()
            total_val_samples += labels.size(0)

    val_losses.append(total_val_loss / len(val_loader))
    val_accuracies.append(correct_val_predictions / total_val_samples)

    print(f"Epoch {epoch+1}/{epochs}, Train Loss: {train_losses[-1]:.4f}, "
          f"Train Accuracy: {train_accuracies[-1]:.4f}, "
          f"Val Loss: {val_losses[-1]:.4f}, Val Accuracy: {val_accuracies[-1]:.4f}")

"""Insight : Model menunjukkan peningkatan performa dari epoch 1 ke epoch 3. Akurasi training naik dari 86.73% ‚Üí 94.09%, sementara akurasi validasi juga meningkat dari 87.35% ‚Üí 89.66%, meskipun val loss sempat naik di epoch 3, yang bisa mengindikasikan awal mula overfitting. Secara keseluruhan, model berhasil belajar dengan baik dan stabil.

#Model Evaluation

Dalam tahap model evaluation ini dilakukan beberapa langkah, yaitu :

* Menghitung akurasi pada data uji.

* Menampilkan classification report (precision, recall, f1-score).

* Menampilkan confusion matrix untuk melihat performa prediksi tiap kelas.
"""

from sklearn.metrics import classification_report, confusion_matrix
import seaborn as sns
import matplotlib.pyplot as plt

# Put model in evaluation mode
model.eval()

# Akurasi pada test set
correct_predictions = 0
total_predictions = 0

with torch.no_grad():
    for batch in val_loader:
        input_ids = batch[0].to(device)
        attention_mask = batch[1].to(device)
        labels = batch[2].to(device)

        outputs = model(input_ids, attention_mask=attention_mask, labels=labels)
        logits = outputs.logits

        predictions = torch.argmax(logits, dim=-1)
        correct_predictions += (predictions == labels).sum().item()
        total_predictions += labels.size(0)

test_accuracy = correct_predictions / total_predictions
print(f"Test Accuracy: {test_accuracy:.4f}")

"""Insight:

Akurasi 0.8966 menunjukkan bahwa model BERT berhasil mengklasifikasikan sekitar **89.66%** ulasan dengan benar pada data uji, menandakan performa yang sangat baik dan generalisasi yang kuat terhadap data baru.

"""

# Kumpulkan semua prediksi dan label
all_predictions = []
all_labels = []

with torch.no_grad():
    for batch in val_loader:
        input_ids = batch[0].to(device)
        attention_mask = batch[1].to(device)
        labels = batch[2].to(device)

        outputs = model(input_ids, attention_mask=attention_mask)
        predictions = torch.argmax(outputs.logits, dim=-1)

        all_predictions.extend(predictions.cpu().numpy())
        all_labels.extend(labels.cpu().numpy())

from sklearn.metrics import classification_report, confusion_matrix

# Classification report
print("Classification Report:")
print(classification_report(all_labels, all_predictions, target_names=["Negative", "Positive"]))

# Confusion matrix
conf_matrix = confusion_matrix(all_labels, all_predictions)

plt.figure(figsize=(8, 6))
sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues',
            xticklabels=["Negative", "Positive"],
            yticklabels=["Negative", "Positive"])
plt.xlabel('Predicted')
plt.ylabel('Actual')
plt.title('Confusion Matrix')
plt.show()

"""Insight:

Model menunjukkan performa yang sangat baik dengan akurasi **90%**. Kelas *Positive* memiliki presisi dan recall tinggi (masing-masing **0.92** dan **0.94**), namun kelas *Negative* masih cukup tertukar (recall **0.77**). Confusion matrix menunjukkan model cenderung lebih akurat dalam mengenali ulasan positif dibanding negatif. Ini bisa diatasi dengan menyeimbangkan data atau melakukan penyesuaian threshold.

#Model Testing

Pada tahapan ini akan dilakukan pengujian model klasifikasi sentimen terhadap teks baru setelah proses training dan evaluasi selesai.
"""

def predict_sentiment(text):
    model.eval()
    inputs = tokenizer(text, truncation=True, padding=True, max_length=128, return_tensors="pt")
    inputs = {key: val.to(device) for key, val in inputs.items()}
    with torch.no_grad():
        outputs = model(**inputs)
        prediction = torch.argmax(outputs.logits, dim=-1).item()

    # Ubah label sesuai dataset kamu
    return ["Negative", "Positive"][prediction]

# Sample English reviews for testing
test_texts = [
    "The service at the hotel was terrible. I'm very disappointed.",
    "The room was clean and comfortable. I had a great stay!",
    "Very satisfied with the quality. Will buy again!",
    "The app works smoothly and is very user-friendly.",
    "It was not what I expected. Definitely not worth the price.",
    "The app keeps crashing and is full of bugs.",
    "I waited two weeks and still haven‚Äôt received my order.",
    "Poor quality and bad packaging.",
    "Waste of money. I won‚Äôt buy from this store again.",
]

# Predict sentiment for each review
for text in test_texts:
    sentiment = predict_sentiment(text)
    print(f"Review: {text}\nPredicted Sentiment: {sentiment}\n")

"""Insight : Model berhasil memprediksi sentimen dengan sangat baik pada semua contoh review. Dari 9 ulasan yang diuji:

‚úÖ 4 review positif ‚Üí diprediksi Positive

‚úÖ 5 review negatif ‚Üí diprediksi Negative


Model dapat:

Memahami konteks positif seperti:
* ‚Äúclean and comfortable‚Äù, ‚Äúgreat stay‚Äù, ‚Äúvery user-friendly‚Äù

* Mengenali konteks negatif seperti:
‚Äúdisappointed‚Äù, ‚Äúbugs‚Äù, ‚Äúpoor quality‚Äù, ‚Äúwaste of money‚Äù

Kesimpulan
Model menunjukkan kemampuan generalisasi yang baik terhadap teks baru dan memiliki potensi kuat untuk digunakan dalam skenario nyata seperti analisis ulasan pengguna.

"""